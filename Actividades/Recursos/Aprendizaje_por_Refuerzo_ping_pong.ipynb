{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpZs0jCNVIZ4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "from time import sleep\n",
        "from IPython.display import clear_output\n",
        "from math import ceil,floor\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase Agente"
      ],
      "metadata": {
        "id": "_I5Gfbx8VPsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PongAgent:\n",
        "    \n",
        "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
        "\n",
        "        # Creamos la tabla de politicas\n",
        "        if policy is not None:\n",
        "            self._q_table = policy\n",
        "        else:\n",
        "            position = list(game.positions_space.shape)\n",
        "            position.append(len(game.action_space))\n",
        "            self._q_table = np.zeros(position)\n",
        "        \n",
        "        self.discount_factor = discount_factor\n",
        "        self.learning_rate = learning_rate\n",
        "        self.ratio_explotacion = ratio_explotacion\n",
        "\n",
        "    def get_next_step(self, state, game):\n",
        "        \n",
        "        # Damos un paso aleatorio...\n",
        "        next_step = np.random.choice(list(game.action_space))\n",
        "        \n",
        "        # o tomaremos el mejor paso...\n",
        "        if np.random.uniform() <= self.ratio_explotacion:\n",
        "            # tomar el maximo\n",
        "            idx_action = np.random.choice(np.flatnonzero(\n",
        "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
        "                ))\n",
        "            next_step = list(game.action_space)[idx_action]\n",
        "\n",
        "        return next_step\n",
        "\n",
        "    # actualizamos las politicas con las recompensas obtenidas\n",
        "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
        "        idx_action_taken =list(game.action_space).index(action_taken)\n",
        "\n",
        "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
        "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
        "\n",
        "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
        "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
        "        if reached_end:\n",
        "            future_max_q_value = reward_action_taken #maximum reward\n",
        "\n",
        "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
        "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
        "    \n",
        "    def print_policy(self):\n",
        "        for row in np.round(self._q_table,1):\n",
        "            for column in row:\n",
        "                print('[', end='')\n",
        "                for value in column:\n",
        "                    print(str(value).zfill(5), end=' ')\n",
        "                print('] ', end='')\n",
        "            print('')\n",
        "            \n",
        "    def get_policy(self):\n",
        "        return self._q_table"
      ],
      "metadata": {
        "id": "eYUcZU_dVQ69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase Environment"
      ],
      "metadata": {
        "id": "_WmiY_gnVXYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PongEnvironment:\n",
        "    \n",
        "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
        "        \n",
        "        self.action_space = ['Arriba','Abajo']\n",
        "        \n",
        "        self._step_penalization = 0\n",
        "        \n",
        "        self.state = [0,0,0]\n",
        "        \n",
        "        self.total_reward = 0\n",
        "        \n",
        "        self.dx = movimiento_px\n",
        "        self.dy = movimiento_px\n",
        "        \n",
        "        filas = ceil(height_px/movimiento_px)\n",
        "        columnas = ceil(width_px/movimiento_px)\n",
        "        \n",
        "        self.positions_space = np.array([[[0 for z in range(columnas)] \n",
        "                                                  for y in range(filas)] \n",
        "                                                     for x in range(filas)])\n",
        "\n",
        "        self.lives = max_life\n",
        "        self.max_life=max_life\n",
        "        \n",
        "        self.x = randint(int(width_px/2), width_px) \n",
        "        self.y = randint(0, height_px-10)\n",
        "        \n",
        "        self.player_alto = int(height_px/4)\n",
        "\n",
        "        self.player1 = self.player_alto  # posic. inicial del player\n",
        "        \n",
        "        self.score = 0\n",
        "        \n",
        "        self.width_px = width_px\n",
        "        self.height_px = height_px\n",
        "        self.radio = 2.5\n",
        "\n",
        "    def reset(self):\n",
        "        self.total_reward = 0\n",
        "        self.state = [0,0,0]\n",
        "        self.lives = self.max_life\n",
        "        self.score = 0\n",
        "        self.x = randint(int(self.width_px/2), self.width_px) \n",
        "        self.y = randint(0, self.height_px-10)\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action, animate=False):\n",
        "        self._apply_action(action, animate)\n",
        "        done = self.lives <=0 # final\n",
        "        reward = self.score\n",
        "        reward += self._step_penalization\n",
        "        self.total_reward += reward\n",
        "        return self.state, reward , done\n",
        "\n",
        "    def _apply_action(self, action, animate=False):\n",
        "        \n",
        "        if action == \"Arriba\":\n",
        "            self.player1 += abs(self.dy)\n",
        "        elif action == \"Abajo\":\n",
        "            self.player1 -= abs(self.dy)\n",
        "            \n",
        "        self.avanza_player()\n",
        "\n",
        "        self.avanza_frame()\n",
        "\n",
        "        if animate:\n",
        "            clear_output(wait=True);\n",
        "            fig = self.dibujar_frame()\n",
        "            plt.show()\n",
        "\n",
        "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
        "    \n",
        "    def detectaColision(self, ball_y, player_y):\n",
        "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    \n",
        "    def avanza_player(self):\n",
        "        if self.player1 + self.player_alto >= self.height_px:\n",
        "            self.player1 = self.height_px - self.player_alto\n",
        "        elif self.player1 <= -abs(self.dy):\n",
        "            self.player1 = -abs(self.dy)\n",
        "\n",
        "    def avanza_frame(self):\n",
        "        self.x += self.dx\n",
        "        self.y += self.dy\n",
        "        if self.x <= 3 or self.x > self.width_px:\n",
        "            self.dx = -self.dx\n",
        "            if self.x <= 3:\n",
        "                ret = self.detectaColision(self.y, self.player1)\n",
        "\n",
        "                if ret:\n",
        "                    self.score = 10\n",
        "                else:\n",
        "                    self.score = -10\n",
        "                    self.lives -= 1\n",
        "                    if self.lives>0:\n",
        "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
        "                        self.y = randint(0, self.height_px-10)\n",
        "                        self.dx = abs(self.dx)\n",
        "                        self.dy = abs(self.dy)\n",
        "        else:\n",
        "            self.score = 0\n",
        "\n",
        "        if self.y < 0 or self.y > self.height_px:\n",
        "            self.dy = -self.dy\n",
        "\n",
        "    def dibujar_frame(self):\n",
        "        fig = plt.figure(figsize=(5, 4))\n",
        "        a1 = plt.gca()\n",
        "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
        "        a1.set_ylim(-5, self.height_px+5)\n",
        "        a1.set_xlim(-5, self.width_px+5)\n",
        "\n",
        "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
        "        a1.add_patch(circle);\n",
        "        a1.add_patch(rectangle)\n",
        "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
        "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
        "        if self.lives <=0:\n",
        "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
        "        elif self.total_reward >= 1000:\n",
        "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
        "        return fig"
      ],
      "metadata": {
        "id": "k6ytjGK4VYGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Juego"
      ],
      "metadata": {
        "id": "DV5TKpjuVfXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
        "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
        "\n",
        "    if game is None:\n",
        "        # si usamos movimiento_px = 5 creamos una tabla de politicas de 8x10\n",
        "        # si usamos movimiento_px = 3 la tabla sera de 14x17\n",
        "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
        "        \n",
        "    if learner is None:\n",
        "        print(\"Begin new Train!\")\n",
        "        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
        "\n",
        "    max_points= -9999\n",
        "    first_max_reached = 0\n",
        "    total_rw=0\n",
        "    steps=[]\n",
        "\n",
        "    for played_games in range(0, rounds):\n",
        "        state = game.reset()\n",
        "        reward, done = None, None\n",
        "        \n",
        "        itera=0\n",
        "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
        "            old_state = np.array(state)\n",
        "            next_action = learner.get_next_step(state, game)\n",
        "            state, reward, done = game.step(next_action, animate=animate)\n",
        "            if rounds > 1:\n",
        "                learner.update(game, old_state, next_action, reward, state, done)\n",
        "            itera+=1\n",
        "        \n",
        "        steps.append(itera)\n",
        "        \n",
        "        total_rw+=game.total_reward\n",
        "        if game.total_reward > max_points:\n",
        "            max_points=game.total_reward\n",
        "            first_max_reached = played_games\n",
        "        \n",
        "        if played_games %500==0 and played_games >1 and not animate:\n",
        "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
        "                \n",
        "    if played_games>1:\n",
        "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
        "        \n",
        "    #learner.print_policy()\n",
        "    \n",
        "    return learner, game"
      ],
      "metadata": {
        "id": "R-jchq6PVi61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner, game = play(rounds=5000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QOe-gNNVlFP",
        "outputId": "3c3965ed-590c-44f9-a812-13ccd778872e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin new Train!\n",
            "-- Partidas[ 500 ] Avg.Puntos[ 18 ]  AVG Steps[ 234 ] Max Score[ 130 ]\n",
            "-- Partidas[ 1000 ] Avg.Puntos[ 23 ]  AVG Steps[ 249 ] Max Score[ 150 ]\n",
            "-- Partidas[ 1500 ] Avg.Puntos[ 26 ]  AVG Steps[ 259 ] Max Score[ 150 ]\n",
            "-- Partidas[ 2000 ] Avg.Puntos[ 28 ]  AVG Steps[ 265 ] Max Score[ 180 ]\n",
            "-- Partidas[ 2500 ] Avg.Puntos[ 31 ]  AVG Steps[ 277 ] Max Score[ 310 ]\n",
            "-- Partidas[ 3000 ] Avg.Puntos[ 34 ]  AVG Steps[ 287 ] Max Score[ 310 ]\n",
            "-- Partidas[ 3500 ] Avg.Puntos[ 34 ]  AVG Steps[ 287 ] Max Score[ 310 ]\n",
            "-- Partidas[ 4000 ] Avg.Puntos[ 35 ]  AVG Steps[ 289 ] Max Score[ 330 ]\n",
            "-- Partidas[ 4500 ] Avg.Puntos[ 35 ]  AVG Steps[ 291 ] Max Score[ 410 ]\n",
            "Partidas[ 4999 ] Avg.Puntos[ 36 ] Max score[ 410 ] en partida[ 4487 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner2 = PongAgent(game, policy=learner.get_policy())\n",
        "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
        "player = play(rounds=1, learner=learner2, game=game, animate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "tmEzPnClVulx",
        "outputId": "d0b3497f-1b54-4423-e7bb-347ba8d18b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}